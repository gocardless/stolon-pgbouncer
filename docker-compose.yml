---
version: "3.7"

services:
  etcd-store:
    image: quay.io/coreos/etcd:v3.2.17
    restart: on-failure
    entrypoint:
      - etcd
    command:
      - --data-dir=/data
      - --listen-client-urls=http://0.0.0.0:2379
      - --advertise-client-urls=http://0.0.0.0:2379
    volumes:
      - etcd-store-data:/data
    ports:
      - "2379:2379"
    networks:
      default:
        aliases:
          - etcd-store

  sentinel:
    image: &stolonDevelopmentImage gocardless/stolon-development:2019100101
    restart: on-failure
    depends_on:
      - etcd-store
    entrypoint:
      - /usr/local/bin/stolon-sentinel
      - --cluster-name=main
      - --store-backend=etcdv3
      - --store-endpoints=etcd-store:2379
      - --metrics-listen-address=0.0.0.0:9459

  pgbouncer:
    hostname: pgbouncer
    image: *stolonDevelopmentImage
    command:
      - /stolon-pgbouncer/docker/stolon-development/supervisord-pgbouncer.conf
    restart: on-failure
    volumes:
      - .:/stolon-pgbouncer
    ports:
      - "6432:6432"
    depends_on:
      - keeper0
      - keeper1
      - keeper2

  keeper0:
    hostname: keeper0
    image: *stolonDevelopmentImage
    command:
      - /stolon-pgbouncer/docker/stolon-development/supervisord.conf
    restart: on-failure
    volumes:
      - keeper0-data:/data
      - .:/stolon-pgbouncer
    ports:
      - "6433:6432"
    depends_on:
      - sentinel

  keeper1:
    hostname: keeper1
    image: *stolonDevelopmentImage
    command:
      - /stolon-pgbouncer/docker/stolon-development/supervisord.conf
    restart: on-failure
    volumes:
      - keeper1-data:/data
      - .:/stolon-pgbouncer
    ports:
      - "6434:6432"
    depends_on:
      - sentinel

  keeper2:
    hostname: keeper2
    image: *stolonDevelopmentImage
    command:
      - /stolon-pgbouncer/docker/stolon-development/supervisord.conf
    restart: on-failure
    volumes:
      - keeper2-data:/data
      - .:/stolon-pgbouncer
    ports:
      - "6435:6432"
    depends_on:
      - sentinel

  prometheus:
    image: prom/prometheus
    volumes:
      - ./docker/observability/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./docker/observability/prometheus/rules.yml:/etc/prometheus/rules.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    restart: always
    ports:
      - 9090:9090

  grafana:
    image: grafana/grafana
    depends_on:
      - prometheus
    volumes:
      - ./docker/observability/grafana/dashboards:/var/lib/grafana/dashboards
      - ./docker/observability/grafana/dashboard-provisioner.yml:/etc/grafana/provisioning/dashboards/provisioner.yml
      - ./docker/observability/grafana/datasource-provisioner.yml:/etc/grafana/provisioning/datasources/provisioner.yml
      - grafana-data:/var/lib/grafana
    user: "472"
    ports:
      - 3000:3000
    restart: always

# Persist etcd and keeper data across docker restarts. This enables our cluster
# to outlive killing our containers, as the keepers otherwise complain that
# their data went missing.
volumes:
  etcd-store-data:
  keeper0-data:
  keeper1-data:
  keeper2-data:
  prometheus-data:
  grafana-data:

networks:
  default:
    driver: bridge
